{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easydict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from maml.utils import load_dataset, load_model, update_parameters\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logs(dataset, model, shot1_filename, shot5_filename, mode='valid'):\n",
    "    fig, axes = plt.subplots(1, 2, sharey=False, figsize=(16,8))\n",
    "    error = mode + '_error'\n",
    "    accuracy = mode + '_accuracy'\n",
    "    colors = ['green', 'blue', 'red']\n",
    "    \n",
    "    error_logs_list = []\n",
    "    accuracy_logs_list = []\n",
    "    \n",
    "    for filename in shot1_filename:\n",
    "        file_logs = pd.read_csv(filename)\n",
    "        error_logs_list.append(np.array(file_logs[error]))\n",
    "        accuracy_logs_list.append(np.array(file_logs[accuracy]))\n",
    "        \n",
    "    for idx, (filename, error_logs) in enumerate(zip(shot1_filename, error_logs_list)):\n",
    "        axes[0].plot(error_logs.nonzero()[0], error_logs[error_logs.nonzero()[0]], label=filename.split(\"/\")[7], color=colors[idx], linestyle='--')\n",
    "    axes[0].set_ylim([0.0, 3.0])\n",
    "    axes[0].legend()\n",
    "\n",
    "    for idx, (filename, accuracy_logs) in enumerate(zip(shot1_filename, accuracy_logs_list)):\n",
    "        axes[1].plot(accuracy_logs.nonzero()[0], accuracy_logs[accuracy_logs.nonzero()[0]], label=filename.split(\"/\")[7], color=colors[idx], linestyle='--')\n",
    "    axes[1].set_ylim([0.2, 0.75])\n",
    "    if dataset == 'fc100':\n",
    "        axes[1].set_ylim([0.2, 0.55])\n",
    "    axes[1].legend()\n",
    "\n",
    "    \n",
    "    error_logs_list = []\n",
    "    accuracy_logs_list = []\n",
    "    \n",
    "    for filename in shot5_filename:\n",
    "        file_logs = pd.read_csv(filename)\n",
    "        error_logs_list.append(np.array(file_logs[error]))\n",
    "        accuracy_logs_list.append(np.array(file_logs[accuracy]))\n",
    "        \n",
    "    for idx, (filename, error_logs) in enumerate(zip(shot5_filename, error_logs_list)):\n",
    "        axes[0].plot(error_logs.nonzero()[0], error_logs[error_logs.nonzero()[0]], label=filename.split(\"/\")[7], color=colors[idx])\n",
    "    axes[0].set_ylim([0.0, 3.0])\n",
    "    axes[0].legend()\n",
    "\n",
    "    for idx, (filename, accuracy_logs) in enumerate(zip(shot5_filename, accuracy_logs_list)):\n",
    "        axes[1].plot(accuracy_logs.nonzero()[0], accuracy_logs[accuracy_logs.nonzero()[0]], label=filename.split(\"/\")[7], color=colors[idx])\n",
    "    axes[1].set_ylim([0.2, 0.8])\n",
    "    if dataset == 'fc100':\n",
    "        axes[1].set_ylim([0.2, 0.55])\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'miniimagenet' # miniimagenet, tieredimagenet, cifar_fs, fc100\n",
    "model = 'smallconv' # smallconv, largeconv, resnet\n",
    "\n",
    "shot1_path = '/home/osilab7/hdd/jhoon_maml_backup/exp1/1shot_results'\n",
    "shot1_file_list = os.listdir(shot1_path)\n",
    "shot1_file_list = sorted([f for f in shot1_file_list if dataset in f and model in f])\n",
    "\n",
    "shot5_path = '/home/osilab7/hdd/jhoon_maml_backup/exp1/5shot_results'\n",
    "shot5_file_list = os.listdir(shot5_path)\n",
    "shot5_file_list = sorted([f for f in shot5_file_list if dataset in f and model in f])\n",
    "\n",
    "shot1_filename = ['{}/{}/logs/logs.csv'.format(shot1_path, f) for f in shot1_file_list]\n",
    "shot5_filename = ['{}/{}/logs/logs.csv'.format(shot5_path, f) for f in shot5_file_list]\n",
    "\n",
    "plot_logs(dataset, model, shot1_filename, shot5_filename, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1000 episodes test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_task(dataset):\n",
    "    sample_task = dataset.sample_task()\n",
    "    for idx, (image, label) in enumerate(sample_task['train']):\n",
    "        if idx == 0:\n",
    "            s_images = image.unsqueeze(0)\n",
    "            s_labels = [label]\n",
    "            s_real_labels = [sample_task['train'].index[label]]\n",
    "        else:\n",
    "            s_images = torch.cat([s_images, image.unsqueeze(0)], dim=0)\n",
    "            s_labels.append(label)\n",
    "            s_real_labels.append(sample_task['train'].index[label])\n",
    "    \n",
    "    for idx, (image, label) in enumerate(sample_task['test']):\n",
    "        if idx == 0:\n",
    "            q_images = image.unsqueeze(0)\n",
    "            q_labels = [label]\n",
    "            q_real_labels = [sample_task['test'].index[label]]\n",
    "        else:\n",
    "            q_images = torch.cat([q_images, image.unsqueeze(0)], dim=0)\n",
    "            q_labels.append(label)\n",
    "            q_real_labels.append(sample_task['test'].index[label])\n",
    "    \n",
    "    s_labels = torch.tensor(s_labels).type(torch.LongTensor)\n",
    "    s_real_labels = torch.tensor(s_real_labels).type(torch.LongTensor)\n",
    "    q_labels = torch.tensor(q_labels).type(torch.LongTensor)\n",
    "    q_real_labels = torch.tensor(q_real_labels).type(torch.LongTensor)\n",
    "    return [s_images, s_labels, s_real_labels, q_images, q_labels, q_real_labels]\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def get_arguments(path, dataset, save_name):\n",
    "    filename = '{}/{}_{}/logs/arguments.txt'.format(path, dataset, save_name)\n",
    "\n",
    "    args = easydict.EasyDict()\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            key, val = line.split(\": \")\n",
    "            if '\\n' in val:\n",
    "                val = val[:-1]\n",
    "            if isfloat(val):\n",
    "                if val.isdigit():\n",
    "                    val = int(val)\n",
    "                else:\n",
    "                    val = float(val)\n",
    "            if val == 'True' or val == 'False':\n",
    "                val = val == 'True'\n",
    "            args[key] = val\n",
    "    return args\n",
    "\n",
    "def print_accuracy(args, sample_tasks, meta_mode, inner_update_number, criterion=None):\n",
    "    device = torch.device(args.device)\n",
    "    sample_number = len(sample_tasks)\n",
    "    \n",
    "    index = ['task{}'.format(str(i+1)) for i in range(sample_number)]\n",
    "    columns = ['Accuracy on support set (before adaptation)']\n",
    "    for i in range(inner_update_number):\n",
    "        columns.append('Accuracy on support set (after {} adaptation)'.format(i+1))\n",
    "        columns.append('Accuracy on query set (after {} adaptation)'.format(i+1))\n",
    "    filename_pd = '{}/{}_{}/logs/{}_results.csv'.format(args.output_folder, args.dataset, args.save_name, meta_mode)\n",
    "    test_pd = pd.DataFrame(np.zeros([sample_number, len(columns)]), index=index, columns=columns)\n",
    "    \n",
    "    model = load_model(args)\n",
    "    \n",
    "    filename = '{}/{}_{}/logs/logs.csv'.format(args.output_folder, args.dataset, args.save_name)\n",
    "    logs = pd.read_csv(filename)\n",
    "    \n",
    "    if criterion == 'error':\n",
    "        valid_logs = list(logs[logs['valid_error']!=0]['valid_error'])\n",
    "        best_valid_epochs = (valid_logs.index(min(valid_logs))+1)*args.train_batches\n",
    "    elif criterion == 'accuracy':\n",
    "        valid_logs = list(logs[logs['valid_accuracy']!=0]['valid_accuracy'])\n",
    "        best_valid_epochs = (valid_logs.index(max(valid_logs))+1)*args.train_batches\n",
    "    \n",
    "    checkpoint = '{}/{}_{}/models/epochs_{}.pt'.format(args.output_folder, args.dataset, args.save_name, best_valid_epochs)\n",
    "    checkpoint = torch.load(checkpoint, map_location=device)\n",
    "    \n",
    "    for idx in tqdm(range(sample_number)):\n",
    "        task_log = []\n",
    "               \n",
    "        model.load_state_dict(checkpoint, strict=True)\n",
    "        \n",
    "        cos = torch.nn.CosineSimilarity(dim=1)\n",
    "        distances = torch.zeros([5, 5])\n",
    "        for i in range(len(model.classifier.weight.data)):\n",
    "            distances[i] = cos(torch.cat([model.classifier.weight.data[i].unsqueeze(0)]*5, dim=0), model.classifier.weight.data)\n",
    "            distances[i,i] = 0.\n",
    "            \n",
    "        print (torch.sum(distances)/20.)\n",
    "        model.to(device)\n",
    "\n",
    "        support_input = sample_tasks[idx][0].to(device)\n",
    "        support_target = sample_tasks[idx][1].to(device)\n",
    "        support_real_target = sample_tasks[idx][2]\n",
    "        query_input = sample_tasks[idx][3].to(device)\n",
    "        query_target = sample_tasks[idx][4].to(device)\n",
    "        query_real_target = sample_tasks[idx][5]\n",
    "\n",
    "        model.train()\n",
    "        support_features, support_logit = model(support_input)\n",
    "        _, support_pred_target = torch.max(support_logit, dim=1)\n",
    "        task_log.append((sum(support_target==support_pred_target)/float(len(support_target))).item())\n",
    "        \n",
    "        for number in range(inner_update_number):\n",
    "            inner_loss = F.cross_entropy(support_logit, support_target)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            params = update_parameters(model, inner_loss, extractor_step_size=args.extractor_step_size, classifier_step_size=args.classifier_step_size, first_order=args.first_order)\n",
    "            model.load_state_dict(params, strict=False)\n",
    "            \n",
    "            support_features, support_logit = model(support_input)\n",
    "            _, support_pred_target = torch.max(support_logit, dim=1)\n",
    "            \n",
    "            query_features, query_logit = model(query_input)\n",
    "            _, query_pred_target = torch.max(query_logit, dim=1)\n",
    "                        \n",
    "            task_log.append((sum(support_target==support_pred_target)/float(len(support_target))).item())\n",
    "            task_log.append((sum(query_target==query_pred_target)/float(len(query_target))).item())\n",
    "               \n",
    "        test_pd.iloc[idx] = task_log\n",
    "    test_pd.loc[sample_number+1], test_pd.loc[sample_number+2] = test_pd.mean(axis=0), test_pd.std(axis=0)\n",
    "    test_pd.index = list(test_pd.index[:sample_number]) + ['mean', 'std']\n",
    "    test_pd.to_csv(filename_pd)\n",
    "    \n",
    "def get_similarity(args, sample_tasks, meta_mode, inner_update_number, checkpoint_epoch):\n",
    "    device = torch.device(args.device)\n",
    "    sample_number = len(sample_tasks)\n",
    "    \n",
    "    model = load_model(args)\n",
    "    \n",
    "    checkpoint = '{}/{}_{}/models/epochs_{}.pt'.format(args.output_folder, args.dataset, args.save_name, checkpoint_epoch)\n",
    "    checkpoint = torch.load(checkpoint, map_location=device)\n",
    "    \n",
    "    for idx in range(sample_number):      \n",
    "        model.load_state_dict(checkpoint, strict=True)\n",
    "        \n",
    "        cos = torch.nn.CosineSimilarity(dim=1)\n",
    "        distances = torch.zeros([5, 5])\n",
    "        for i in range(len(model.classifier.weight.data)):\n",
    "            distances[i] = cos(torch.cat([model.classifier.weight.data[i].unsqueeze(0)]*5, dim=0), model.classifier.weight.data)\n",
    "            distances[i,i] = 0.\n",
    "        before_fc_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        model.to(device)\n",
    "\n",
    "        support_input = sample_tasks[idx][0].to(device)\n",
    "        support_target = sample_tasks[idx][1].to(device)\n",
    "        support_real_target = sample_tasks[idx][2]\n",
    "        query_input = sample_tasks[idx][3].to(device)\n",
    "        query_target = sample_tasks[idx][4].to(device)\n",
    "        query_real_target = sample_tasks[idx][5]\n",
    "\n",
    "        model.train()\n",
    "        support_features, support_logit = model(support_input)\n",
    "        _, support_pred_target = torch.max(support_logit, dim=1)\n",
    "        \n",
    "        query_features, query_logit = model(query_input)\n",
    "        _, query_pred_target = torch.max(query_logit, dim=1)\n",
    "        \n",
    "        distances = torch.cdist(support_features, support_features)\n",
    "        before_support_features_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(support_logit, support_logit)\n",
    "        before_support_logits_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(query_features, query_features)\n",
    "        before_query_features_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(query_logit, query_logit)\n",
    "        before_query_logits_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "\n",
    "        for number in range(inner_update_number):\n",
    "            inner_loss = F.cross_entropy(support_logit, support_target)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            params = update_parameters(model, inner_loss, extractor_step_size=args.extractor_step_size, classifier_step_size=args.classifier_step_size, first_order=args.first_order)\n",
    "            model.load_state_dict(params, strict=False)\n",
    "            \n",
    "            support_features, support_logit = model(support_input)\n",
    "            _, support_pred_target = torch.max(support_logit, dim=1)\n",
    "            \n",
    "            query_features, query_logit = model(query_input)\n",
    "            _, query_pred_target = torch.max(query_logit, dim=1)\n",
    "        \n",
    "        distances = torch.zeros([5, 5])\n",
    "        for i in range(len(model.classifier.weight.data)):\n",
    "            distances[i] = cos(torch.cat([model.classifier.weight.data[i].unsqueeze(0)]*5, dim=0), model.classifier.weight.data)\n",
    "            distances[i,i] = 0.\n",
    "        after_fc_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(support_features, support_features)\n",
    "        after_support_features_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(support_logit, support_logit)\n",
    "        after_support_logits_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(query_features, query_features)\n",
    "        after_query_features_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        distances = torch.cdist(query_logit, query_logit)\n",
    "        after_query_logits_similarity = torch.sum(distances)/(len(distances)*len(distances)-len(distances))\n",
    "        \n",
    "        return (before_fc_similarity.item(), after_fc_similarity.item(),\n",
    "                before_support_features_similarity.item(), after_support_features_similarity.item(),\n",
    "                before_support_logits_similarity.item(), after_support_logits_similarity.item(),\n",
    "                before_query_features_similarity.item(), after_query_features_similarity.item(),\n",
    "                before_query_logits_similarity.item(), after_query_logits_similarity.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 1\n",
    "dataset = 'miniimagenet' # miniimagenet, tieredimagenet, cifar_fs, fc100\n",
    "num_shots = 5 # 1, 5\n",
    "dataset_args = easydict.EasyDict({'folder': '/home/osilab7/hdd/ml_dataset',\n",
    "                                  'dataset': dataset,\n",
    "                                  'num_ways': 5,\n",
    "                                  'num_shots': num_shots,\n",
    "                                  'download': True})\n",
    "\n",
    "train_tasks = [make_sample_task(load_dataset(dataset_args, 'meta_train')) for _ in tqdm(range(sample_number))]\n",
    "test_tasks = [make_sample_task(load_dataset(dataset_args, 'meta_test')) for _ in tqdm(range(sample_number))]\n",
    "\n",
    "inner_update_number = 1\n",
    "criterion = 'error' # error, accuracy\n",
    "\n",
    "path = '/home/osilab7/hdd/jhoon_maml_backup/exp1/1shot_results' if num_shots == 1 else '/home/osilab7/hdd/jhoon_maml_backup/exp1/5shot_results'\n",
    "for model in ['smallconv']: # smallconv, largeconv, resnet\n",
    "    for algorithm in ['both']: # both, extractor, classifier\n",
    "        save_name = '{}shot_{}_{}'.format(num_shots, model, algorithm)\n",
    "        args = get_arguments(path, dataset, save_name)\n",
    "        args.folder = '/home/osilab7/hdd/ml_dataset'\n",
    "        args.device = 'cuda:0'\n",
    "        args.output_folder = path\n",
    "        print_accuracy(args, train_tasks, meta_mode='meta_train', inner_update_number=inner_update_number, criterion=criterion)\n",
    "        print_accuracy(args, test_tasks, meta_mode='meta_test', inner_update_number=inner_update_number, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 1\n",
    "dataset = 'miniimagenet' # miniimagenet, tieredimagenet, cifar_fs, fc100\n",
    "num_shots = 5 # 1, 5\n",
    "dataset_args = easydict.EasyDict({'folder': '/home/osilab7/hdd/ml_dataset',\n",
    "                                  'dataset': dataset,\n",
    "                                  'num_ways': 5,\n",
    "                                  'num_shots': num_shots,\n",
    "                                  'download': True})\n",
    "\n",
    "train_tasks = [make_sample_task(load_dataset(dataset_args, 'meta_train')) for _ in tqdm(range(sample_number))]\n",
    "test_tasks = [make_sample_task(load_dataset(dataset_args, 'meta_test')) for _ in tqdm(range(sample_number))]\n",
    "\n",
    "inner_update_number = 1\n",
    "before_fc_similarity_list = []\n",
    "after_fc_similarity_list = []\n",
    "before_support_features_similarity_list = []\n",
    "after_support_features_similarity_list = []\n",
    "before_support_logits_similarity_list = []\n",
    "after_support_logits_similarity_list = []\n",
    "before_query_features_similarity_list = []\n",
    "after_query_features_similarity_list = []\n",
    "before_query_logits_similarity_list = []\n",
    "after_query_logits_similarity_list = []\n",
    "\n",
    "path = '/home/osilab7/hdd/jhoon_maml_backup/exp1/1shot_results' if num_shots == 1 else '/home/osilab7/hdd/jhoon_maml_backup/exp1/5shot_results'\n",
    "for model in ['smallconv']: # resnet 추가\n",
    "    for algorithm in ['both']:\n",
    "        for checkpoint_epoch in range(100, 60001, 100):\n",
    "            save_name = '{}shot_{}_{}'.format(num_shots, model, algorithm)\n",
    "            args = get_arguments(path, dataset, save_name)\n",
    "            args.folder = '/home/osilab7/hdd/ml_dataset'\n",
    "            args.device = 'cuda:0'\n",
    "            args.output_folder = path\n",
    "            outputs = get_similarity(args, train_tasks, meta_mode='meta_train', inner_update_number=inner_update_number, checkpoint_epoch=checkpoint_epoch)\n",
    "            before_fc_similarity_list.append(outputs[0]); after_fc_similarity_list.append(outputs[1])\n",
    "            before_support_features_similarity_list.append(outputs[2]); after_support_features_similarity_list.append(outputs[3])\n",
    "            before_support_logits_similarity_list.append(outputs[4]); after_support_logits_similarity_list.append(outputs[5])\n",
    "            before_query_features_similarity_list.append(outputs[6]); after_query_features_similarity_list.append(outputs[7])\n",
    "            before_query_logits_similarity_list.append(outputs[8]); after_query_logits_similarity_list.append(outputs[9])\n",
    "            # get_similarity(args, test_tasks, meta_mode='meta_test', inner_update_number=inner_update_number, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before_fc_similarity_list (0)\n",
    "# after_fc_simiaafter_fc_similarity_list (1)\n",
    "# before_support_features_similarity_list (2)\n",
    "# after_support_features_similarity_list (3)\n",
    "# before_support_logits_similarity_list (4)\n",
    "# after_support_logits_similarity_list (5)\n",
    "# before_query_features_similarity_list (6)\n",
    "# after_query_features_similarity_list (7)\n",
    "# before_query_logits_similarity_list (8)\n",
    "# after_query_logits_similarity_list (9)\n",
    "# extractor의 역할을 살피기 위해 feature space 간의 거리를 살핌\n",
    "# classifier의 역할을 살피기 위해 feature space와 logit space를 살피고 어떻게 mapping 되는 지를 봄 + fc weight의 similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
