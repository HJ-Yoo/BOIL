{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easydict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from maml.utils import load_dataset, load_model, update_parameters, get_accuracy, get_graph_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'folder': './dataset',\n",
    "                          'dataset': 'miniimagenet',\n",
    "                          'device': 'cuda:1',\n",
    "                          'download': True,\n",
    "                          'num_shots': 5,\n",
    "                          'num_ways': 5,\n",
    "                          'meta_lr': 1e-3,\n",
    "                          'first_order': False,\n",
    "                          'step_size': 0.7,\n",
    "                          'hidden_size': 64,\n",
    "                          'output_folder': './output/',\n",
    "                          'save_name': None,\n",
    "                          'batch_size': 4,\n",
    "                          'batch_iter': 1200,\n",
    "                          'train_batches': 50,\n",
    "                          'valid_batches': 25,\n",
    "                          'test_batches': 2500,\n",
    "                          'num_workers': 1,\n",
    "                          'graph_gamma': 5.0,\n",
    "                          'graph_beta': 1e-5,\n",
    "                          'graph_regularizer': False,\n",
    "                          'fc_regularizer': False,\n",
    "                          'task_embedding_method': None,\n",
    "                          'edge_generation_method': None,\n",
    "                          'best_valid_error_test': False,\n",
    "                          'best_valid_accuracy_test': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task_embedding_method = 'gcn'\n",
    "args.edge_generation_method = 'max_normalization'\n",
    "args.save_name = 'te_gcn_maxnorm_l1_output_normalization'\n",
    "args.best_valid_error_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(args)\n",
    "filename = './output/miniimagenet_{}/logs/logs.csv'.format(args.save_name)\n",
    "logs = pd.read_csv(filename)\n",
    "\n",
    "if args.best_valid_error_test:\n",
    "    valid_logs = list(logs[logs['valid_error']!=0]['valid_error'])\n",
    "    best_valid_epochs = (valid_logs.index(min(valid_logs))+1)*50\n",
    "else:\n",
    "    valid_logs = list(logs[logs['valid_accuracy']!=0]['valid_accuracy'])\n",
    "    best_valid_epochs = (valid_logs.index(max(valid_logs))+1)*50\n",
    "\n",
    "best_valid_model = torch.load('./output/miniimagenet_{}/models/epochs_{}.pt'.format(args.save_name, best_valid_epochs))\n",
    "\n",
    "mode = 'meta_test'\n",
    "dataset = load_dataset(args, mode)\n",
    "dataloader = BatchMetaDataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 84, 84]) torch.Size([25]) torch.Size([25])\n",
      "torch.Size([75, 3, 84, 84]) torch.Size([75]) torch.Size([75])\n"
     ]
    }
   ],
   "source": [
    "sample_number = 100\n",
    "sample_tasks = []\n",
    "for _ in range(sample_number):\n",
    "    sample_task = dataset.sample_task()\n",
    "    for idx, (image, label) in enumerate(sample_task['train']): # support set in meta_test\n",
    "        if idx == 0:\n",
    "            s_images = image.unsqueeze(0)\n",
    "            s_labels = [label]\n",
    "            s_real_labels = [sample_task['train'].index[label]]\n",
    "        else:\n",
    "            s_images = torch.cat([s_images, image.unsqueeze(0)], dim=0)\n",
    "            s_labels.append(label)\n",
    "            s_real_labels.append(sample_task['train'].index[label])\n",
    "    \n",
    "    for idx, (image, label) in enumerate(sample_task['test']): # query set in meta_test\n",
    "        if idx == 0:\n",
    "            q_images = image.unsqueeze(0)\n",
    "            q_labels = [label]\n",
    "            q_real_labels = [sample_task['test'].index[label]]\n",
    "        else:\n",
    "            q_images = torch.cat([q_images, image.unsqueeze(0)], dim=0)\n",
    "            q_labels.append(label)\n",
    "            q_real_labels.append(sample_task['test'].index[label])\n",
    "    \n",
    "    s_labels = torch.tensor(s_labels).type(torch.LongTensor)\n",
    "    s_real_labels = torch.tensor(s_real_labels).type(torch.LongTensor)\n",
    "    q_labels = torch.tensor(q_labels).type(torch.LongTensor)\n",
    "    q_real_labels = torch.tensor(q_real_labels).type(torch.LongTensor)\n",
    "    sample_tasks.append((s_images, s_labels, s_real_labels, q_images, q_labels, q_real_labels))\n",
    "print (sample_tasks[0][0].shape, sample_tasks[0][1].shape, sample_tasks[0][2].shape)\n",
    "print (sample_tasks[0][3].shape, sample_tasks[0][4].shape, sample_tasks[0][5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19919999405741692 0.9775999885797501 0.6581333476305008\n"
     ]
    }
   ],
   "source": [
    "before_support_accuracy_list = []\n",
    "after_support_accuracy_list = []\n",
    "after_query_accuracy_list = []\n",
    "\n",
    "for idx in range(sample_number):\n",
    "    model.load_state_dict(best_valid_model)\n",
    "    model.to(args.device)\n",
    "    # model.classifier.weight.data.fill_(1.)\n",
    "    # model.classifier.bias.data.fill_(1.)\n",
    "\n",
    "    support_input = sample_tasks[idx][0].to(args.device)\n",
    "    support_target = sample_tasks[idx][1].to(args.device)\n",
    "    support_real_target = sample_tasks[idx][2]\n",
    "    query_input = sample_tasks[idx][3].to(args.device)\n",
    "    query_target = sample_tasks[idx][4].to(args.device)\n",
    "    query_real_target = sample_tasks[idx][5]\n",
    "\n",
    "    model.train()\n",
    "    support_features, support_logit = model(support_input)\n",
    "    _, support_pred_target = torch.max(support_logit, dim=1)\n",
    "    before_support_accuracy_list.append(sum(support_target==support_pred_target)/float(len(support_target)))\n",
    "    # print ('before support accuracy: {}'.format(sum(support_target==support_pred_target)/float(len(support_target))))\n",
    "\n",
    "    inner_loss = F.cross_entropy(support_logit, support_target)\n",
    "    model.zero_grad()\n",
    "    params = update_parameters(model, inner_loss, step_size=args.step_size, first_order=args.first_order)\n",
    "\n",
    "    support_features, support_logit = model(support_input, params=params) # inner loss를 통해 적어도 1번이라도 업데이트 되었을 때 (params=params 들어갔을 떄), 제대로된 task_embedding이 뽑힘. 근데 뽑는다 한들 어떻게 합치지;;\n",
    "    _, support_pred_target = torch.max(support_logit, dim=1)\n",
    "    after_support_accuracy_list.append(sum(support_target==support_pred_target)/float(len(support_target)))\n",
    "    # print ('after support accuracy: {}'.format(sum(support_target==support_pred_target)/float(len(support_target))))\n",
    "\n",
    "    query_features, query_logit = model(query_input, params=params)\n",
    "    _, query_pred_target = torch.max(query_logit, dim=1)\n",
    "    after_query_accuracy_list.append(sum(query_target==query_pred_target)/float(len(query_target)))\n",
    "    # print ('query accuracy: {}'.format(sum(query_target==query_pred_target)/float(len(query_target))))\n",
    "    \n",
    "before_support_accuracy_list = [v.cpu().item() for v in before_support_accuracy_list]\n",
    "after_support_accuracy_list = [v.cpu().item() for v in after_support_accuracy_list]\n",
    "after_query_accuracy_list = [v.cpu().item() for v in after_query_accuracy_list]\n",
    "\n",
    "print (np.mean(before_support_accuracy_list), np.mean(after_support_accuracy_list), np.mean(after_query_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca (일단 임의로 features의 mean을 task embedding 이라고 함)\n",
    "embedded_tasks = []\n",
    "for idx in enumerate(sample_tasks):\n",
    "    print (sample_task[2])\n",
    "    for (image, label, real_label) in sample_task.:\n",
    "        features, out = model(image)\n",
    "        embedded_tasks.append(torch.mean(features, dim=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
